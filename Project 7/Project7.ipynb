{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:  Best-subset regression and lasso regression\n",
    "Consider the `Boston` data set in package `MASS`.  Let 'medv' be the response variable.\n",
    "- 'crim'  per capita crime rate by town.\n",
    "- 'zn' proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- 'indus' proportion of non-retail business acres per town.\n",
    "- 'chas' Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).\n",
    "- 'nox' nitrogen oxides concentration (parts per 10 million).\n",
    "- 'rm' average number of rooms per dwelling.\n",
    "- 'age' proportion of owner-occupied units built prior to 1940.\n",
    "- 'dis' weighted mean of distances to five Boston employment centres.\n",
    "- 'rad' index of accessibility to radial highways.\n",
    "- 'tax' full-value property-tax rate per $10,000.\n",
    "- 'ptratio' pupil-teacher ratio by town.\n",
    "- 'black' 1000$(Bk-0.63)^2$ where Bk is the proportion of blacks by town.\n",
    "- 'lstat' lower status of the population (percent).\n",
    "- 'medv' median value of owner-occupied homes in $1000s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
      "       'ptratio', 'black', 'lstat', 'medv'],\n",
      "      dtype='object')\n",
      "(506, 14)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "Boston = sm.datasets.get_rdataset(\"Boston\", \"MASS\").data\n",
    "print(Boston.columns)\n",
    "Boston.dropna(inplace=True)\n",
    "print(Boston.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Consider all regression models without interaction effects. Use 10-fold cross validation to conduct best-subset regression.  What is your best model?   If you could not install `abess` package, use forward selection or backward elimination mehtod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: ['lstat', 'rm', 'ptratio', 'dis', 'nox', 'chas', 'black', 'zn', 'crim', 'rad', 'tax']\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   medv   R-squared:                       0.741\n",
      "Model:                            OLS   Adj. R-squared:                  0.734\n",
      "Method:                 Least Squares   F-statistic:                     117.3\n",
      "Date:                Thu, 24 Apr 2025   Prob (F-statistic):          6.08e-136\n",
      "Time:                        19:55:01   Log-Likelihood:                -1498.8\n",
      "No. Observations:                 506   AIC:                             3024.\n",
      "Df Residuals:                     493   BIC:                             3079.\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     36.4369      5.080      7.172      0.000      26.456      46.418\n",
      "lstat         -0.5239      0.048    -10.999      0.000      -0.617      -0.430\n",
      "rm             3.8144      0.408      9.338      0.000       3.012       4.617\n",
      "ptratio       -0.9522      0.130     -7.308      0.000      -1.208      -0.696\n",
      "dis           -1.4786      0.191     -7.757      0.000      -1.853      -1.104\n",
      "nox          -17.7135      3.679     -4.814      0.000     -24.943     -10.484\n",
      "chas           2.6890      0.860      3.128      0.002       1.000       4.378\n",
      "black          0.0093      0.003      3.481      0.001       0.004       0.015\n",
      "zn             0.0463      0.014      3.404      0.001       0.020       0.073\n",
      "crim          -0.1080      0.033     -3.290      0.001      -0.173      -0.043\n",
      "rad            0.3058      0.066      4.627      0.000       0.176       0.436\n",
      "tax           -0.0123      0.004     -3.283      0.001      -0.020      -0.005\n",
      "indus          0.0206      0.061      0.335      0.738      -0.100       0.141\n",
      "==============================================================================\n",
      "Omnibus:                      178.343   Durbin-Watson:                   1.078\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              786.386\n",
      "Skew:                           1.523   Prob(JB):                    1.73e-171\n",
      "Kurtosis:                       8.294   Cond. No.                     1.48e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.48e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Features and response\n",
    "X = Boston.drop(columns='medv')\n",
    "y = Boston['medv']\n",
    "\n",
    "def adjusted_r2(model, X, y):\n",
    "    r2 = model.rsquared\n",
    "    n = X.shape[0]\n",
    "    p = X.shape[1] - 1  # subtract intercept\n",
    "    return 1 - ((1 - r2) * (n - 1)) / (n - p - 1)\n",
    "\n",
    "def forward_selection(X, y):\n",
    "    remaining = list(X.columns)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    best_model = None\n",
    "\n",
    "    while remaining:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = 'medv ~ ' + ' + '.join(selected + [candidate])\n",
    "            model = sm.OLS.from_formula(formula, pd.concat([X, y], axis=1)).fit()\n",
    "            adj_r2 = adjusted_r2(model, X[selected + [candidate]], y)\n",
    "            scores_with_candidates.append((adj_r2, candidate, model))\n",
    "\n",
    "        scores_with_candidates.sort(reverse=True)\n",
    "        best_new_score, best_candidate, best_model = scores_with_candidates[0]\n",
    "\n",
    "        if best_new_score > current_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return selected, best_model\n",
    "\n",
    "selected_features, best_model = forward_selection(X, y)\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(best_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Consider all regression models without interaction effects. Use lasso regression with 10-fold cross validation to choose the tuning parameter.  What is the final model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha: 0.14602012128965022\n",
      "\n",
      "Selected features: ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n",
      "\n",
      "Lasso coefficients:\n",
      "crim      -0.496429\n",
      "zn         0.537587\n",
      "indus     -0.059797\n",
      "chas       0.646017\n",
      "nox       -1.357844\n",
      "rm         2.895350\n",
      "dis       -2.104315\n",
      "rad        0.525318\n",
      "tax       -0.284227\n",
      "ptratio   -1.860406\n",
      "black      0.721842\n",
      "lstat     -3.720770\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "# Features and response\n",
    "X = Boston.drop(columns='medv')\n",
    "y = Boston['medv']\n",
    "\n",
    "# Standardize predictors\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Lasso with 10-fold CV\n",
    "lasso_cv = LassoCV(cv=10, random_state=42)\n",
    "lasso_cv.fit(X_scaled, y)\n",
    "\n",
    "# Print selected alpha and coefficients\n",
    "print(\"Best alpha:\", lasso_cv.alpha_)\n",
    "\n",
    "# Get coefficients and corresponding feature names\n",
    "coef = pd.Series(lasso_cv.coef_, index=X.columns)\n",
    "selected_features = coef[coef != 0].index.tolist()\n",
    "\n",
    "print(\"\\nSelected features:\", selected_features)\n",
    "print(\"\\nLasso coefficients:\")\n",
    "print(coef[coef != 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2  In this question, we will predict the number of applications received using the other variables in the `College` data set (use the first column as index).\n",
    "\n",
    "The data set contains a number of variables for 777 different universities and colleges in the US. The variables are\n",
    "- `Private`: Public/private indicator\n",
    "- `Apps`: Number of applications received\n",
    "- `Accept`: Number of applicants accepted\n",
    "- `Enroll`: Number of new students enrolled\n",
    "- `Top10perc`: New students from top 10% of high school class\n",
    "- `Top25perc`: New students from top 25% of high school class\n",
    "- `F.Undergrad`: Number of full-time undergraduates\n",
    "- `P.Undergrad`: Number of part-time undergraduates\n",
    "- `Outstate`: Out-of-state tuition\n",
    "- `Room.Board`: Room and board costs\n",
    "- `Books`: Estimated book costs\n",
    "- `Personal`: Estimated personal spending\n",
    "- `PhD`: Percent of faculty with Ph.D.â€™s\n",
    "- `Terminal`: Percent of faculty with terminal degree\n",
    "- `S.F.Ratio`: Student/faculty ratio\n",
    "- `perc.alumni`: Percent of alumni who donate\n",
    "- `Expend`: Instructional expenditure per student\n",
    "- `Grad.Rate`: Graduation rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Update the data by converting `Private` as a dummy variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private\n",
      "1    565\n",
      "0    212\n",
      "Name: count, dtype: int64\n",
      "                              Private  Apps  Accept  Enroll  Top10perc  \\\n",
      "Abilene Christian University        1  1660    1232     721         23   \n",
      "Adelphi University                  1  2186    1924     512         16   \n",
      "Adrian College                      1  1428    1097     336         22   \n",
      "Agnes Scott College                 1   417     349     137         60   \n",
      "Alaska Pacific University           1   193     146      55         16   \n",
      "\n",
      "                              Top25perc  F.Undergrad  P.Undergrad  Outstate  \\\n",
      "Abilene Christian University         52         2885          537      7440   \n",
      "Adelphi University                   29         2683         1227     12280   \n",
      "Adrian College                       50         1036           99     11250   \n",
      "Agnes Scott College                  89          510           63     12960   \n",
      "Alaska Pacific University            44          249          869      7560   \n",
      "\n",
      "                              Room.Board  Books  Personal  PhD  Terminal  \\\n",
      "Abilene Christian University        3300    450      2200   70        78   \n",
      "Adelphi University                  6450    750      1500   29        30   \n",
      "Adrian College                      3750    400      1165   53        66   \n",
      "Agnes Scott College                 5450    450       875   92        97   \n",
      "Alaska Pacific University           4120    800      1500   76        72   \n",
      "\n",
      "                              S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
      "Abilene Christian University       18.1           12    7041         60  \n",
      "Adelphi University                 12.2           16   10527         56  \n",
      "Adrian College                     12.9           30    8735         54  \n",
      "Agnes Scott College                 7.7           37   19016         59  \n",
      "Alaska Pacific University          11.9            2   10922         15  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "college = pd.read_csv(\"College.csv\", index_col=0)\n",
    "\n",
    "# Convert 'Private' to dummy variable: 1 for 'Yes', 0 for 'No'\n",
    "college['Private'] = college['Private'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Check the transformation\n",
    "print(college['Private'].value_counts())\n",
    "print(college.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) The following Python code split the data set into a training set and a test set after the original variable `Private` is dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "seed=100\n",
    "X = college.drop(\"Apps\", axis=1)  \n",
    "y = college[\"Apps\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=seed, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "#transform() applies precomputed scaling parameters on the training data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Fit a lasso model on the training set, with $\\lambda$ chosen by crossvalidation. Report the test error obtained, along with the number of non-zero coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (lambda): 13.7486\n",
      "Test MSE: 895794.84\n",
      "Number of non-zero coefficients: 14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Fit Lasso model with 10-fold CV\n",
    "lasso = LassoCV(cv=10, random_state=100)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = lasso.predict(X_test)\n",
    "\n",
    "# Compute test error (MSE)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Number of non-zero coefficients\n",
    "nonzero_coefs = np.sum(lasso.coef_ != 0)\n",
    "\n",
    "# Report results\n",
    "print(f\"Best alpha (lambda): {lasso.alpha_:.4f}\")\n",
    "print(f\"Test MSE: {test_mse:.2f}\")\n",
    "print(f\"Number of non-zero coefficients: {nonzero_coefs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fit a PCR model on the training set, with $M$ chosen by crossvalidation.\n",
    "Report the test error obtained, along with the value of $M$ selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of components (M): 17\n",
      "Test MSE: 913034.36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fit a PCR model with cross-validation to choose M\n",
    "best_m = 0\n",
    "lowest_mse = np.inf\n",
    "mse_scores = []\n",
    "\n",
    "for m in range(1, X_train.shape[1] + 1):\n",
    "    # Create a pipeline with PCA and Linear Regression\n",
    "    pcr = make_pipeline(PCA(n_components=m), LinearRegression())\n",
    "    \n",
    "    # Compute cross-validation MSE\n",
    "    pcr_mse = cross_val_score(pcr, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "    mse_scores.append(np.mean(-pcr_mse))  # MSE is negative, so we negate to get positive values\n",
    "    \n",
    "    # Track the best number of components based on MSE\n",
    "    if np.mean(-pcr_mse) < lowest_mse:\n",
    "        lowest_mse = np.mean(-pcr_mse)\n",
    "        best_m = m\n",
    "\n",
    "# Fit PCR model with the best M\n",
    "pcr_best = make_pipeline(PCA(n_components=best_m), LinearRegression())\n",
    "pcr_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pcr_best.predict(X_test)\n",
    "\n",
    "# Compute test error (MSE)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Report results\n",
    "print(f\"Best number of components (M): {best_m}\")\n",
    "print(f\"Test MSE: {test_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Fit a PLS model on the training set, with $M$ chosen by crossvalidation.\n",
    "Report the test error obtained, along with the value of $M$ selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of components (M): 16\n",
      "Test MSE: 913025.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fit a PLS model with cross-validation to choose M\n",
    "best_m = 0\n",
    "lowest_mse = np.inf\n",
    "\n",
    "for m in range(1, X_train.shape[1] + 1):\n",
    "    # Create a PLS model with the specified number of components\n",
    "    pls = PLSRegression(n_components=m)\n",
    "    \n",
    "    # Compute cross-validation MSE (note we don't need LinearRegression in the pipeline)\n",
    "    pls_mse = cross_val_score(pls, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    # Track the best number of components based on MSE\n",
    "    mean_mse = np.mean(-pls_mse)  # Negate since scoring returns negative MSE\n",
    "    if mean_mse < lowest_mse:\n",
    "        lowest_mse = mean_mse\n",
    "        best_m = m\n",
    "\n",
    "# Fit PLS model with the best M\n",
    "pls_best = PLSRegression(n_components=best_m)\n",
    "pls_best.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pls_best.predict(X_test)\n",
    "\n",
    "# Compute test error (MSE)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Report results\n",
    "print(f\"Best number of components (M): {best_m}\")\n",
    "print(f\"Test MSE: {test_mse:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Comment on the results obtained. How accurately can we predict\n",
    "the number of college applications received? Is there much\n",
    "difference among the test errors resulting from these four approaches?\n",
    "\n",
    "**Ans**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso model had the lowest test MSE, so the lasso model was the best at predicting the number of college applications. However, there was not an immense difference between the models used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
